{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6354da3-2e27-4f74-8c7a-06a43747e5d1",
   "metadata": {},
   "source": [
    "# RLGames Basic guide\n",
    "\n",
    "### task -> wrap: env (gym) -> register: env_configurations -> wrap: RLGPUEnv(vecenv.IVecEnv)\n",
    "### RLGPUEnv(vecenv.IVecEnv) -> register: vecenv.register\n",
    "### Runner -> load: config with task/env name (env_name) -> reset -> run: mode, checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62944ecd-3bdf-4fdf-941a-e79cd8bc058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from rl_games.common import env_configurations, vecenv\n",
    "from rl_games.torch_runner import Runner\n",
    "from rl_games.common.vecenv import IVecEnv\n",
    "from rl_games.common import env_configurations, vecenv\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc846f95-4501-4803-b959-40c2e3d040c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RLGTrainer():\n",
    "    def __init__(self, cfg, cfg_dict, trial=None):\n",
    "        self.cfg = cfg\n",
    "        self.cfg_dict = cfg_dict\n",
    "        self.algo_obs = RLGPUAlgoObserver(trial)\n",
    "\n",
    "\n",
    "    def launch_rlg_hydra(self, env):\n",
    "        # `create_rlgpu_env` is environment construction function which is passed to RL Games and called internally.\n",
    "        # We use the helper function here to specify the environment config.\n",
    "        self.cfg_dict[\"task\"][\"test\"] = self.cfg.test\n",
    "\n",
    "        # register the rl-games adapter to use inside the runner (like registering GYM env)\n",
    "        # (1) regester RLGPU as ENV wrpper/type, alternative to gym.ENV  (type: rl_games.common.vecenv.IVecEnv)\n",
    "        # (2) register our env with name rlgpu and type RLGPU\n",
    "        # (3) in config, add env_name as rlgpu\n",
    "        vecenv.register('RLGPU',\n",
    "                        lambda config_name, num_actors, **kwargs: RLGPUEnv(config_name, num_actors, **kwargs))\n",
    "        env_configurations.register('rlgpu', {\n",
    "            'vecenv_type': 'RLGPU',\n",
    "            'env_creator': lambda **kwargs: env\n",
    "        })\n",
    "\n",
    "        self.rlg_config_dict = omegaconf_to_dict(self.cfg.train)\n",
    "\n",
    "    def run(self, ):\n",
    "        # create runner and set the settings\n",
    "        runner = Runner(self.algo_obs)\n",
    "        runner.load(self.rlg_config_dict)\n",
    "        runner.reset()\n",
    "\n",
    "        # dump config dict\n",
    "        experiment_dir = os.path.join('runs', self.cfg.train.params.config.name)\n",
    "        os.makedirs(experiment_dir, exist_ok=True)\n",
    "        with open(os.path.join(experiment_dir, 'config.yaml'), 'w') as f:\n",
    "            f.write(OmegaConf.to_yaml(self.cfg))\n",
    "\n",
    "        runner.run({\n",
    "            'train': not self.cfg.test,\n",
    "            'play': self.cfg.test,\n",
    "            'checkpoint': self.cfg.checkpoint,\n",
    "            'sigma': None\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd100454-0a71-4b6e-a1a0-b7f8a9162c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RLGPUEnv(vecenv.IVecEnv):\n",
    "    def __init__(self, config_name, num_actors, **kwargs):\n",
    "        self.env = env_configurations.configurations[config_name]['env_creator'](**kwargs)\n",
    "\n",
    "    def step(self, action):\n",
    "        return  self.env.step(action)\n",
    "\n",
    "    def reset(self):\n",
    "        return self.env.reset()\n",
    "\n",
    "    # below functions are optional\n",
    "    \n",
    "    def get_number_of_agents(self):\n",
    "        return self.env.get_number_of_agents()\n",
    "\n",
    "    def get_env_info(self):\n",
    "        info = {}\n",
    "        info['action_space'] = self.env.action_space\n",
    "        info['observation_space'] = self.env.observation_space\n",
    "\n",
    "        if self.env.num_states > 0:\n",
    "            info['state_space'] = self.env.state_space\n",
    "            print(info['action_space'], info['observation_space'], info['state_space'])\n",
    "        else:\n",
    "            print(info['action_space'], info['observation_space'])\n",
    "        \n",
    "        if hasattr(self.env, 'value_size'):\n",
    "            info['value_size'] = self.env.value_size\n",
    "\n",
    "        return info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed948bf0-820e-47bc-b419-2b229604b4a4",
   "metadata": {},
   "source": [
    "### Run standard GYM Env on RLGames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88d23bc8-3912-4578-a638-6f88d7d4cf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'params': {'algo': {'name': 'a2c_discrete'}, 'model': {'name': 'discrete_a2c'}, 'load_checkpoint': False, 'load_path': 'path', 'network': {'name': 'actor_critic', 'separate': True, 'space': {'discrete': None}, 'mlp': {'units': [32, 32], 'activation': 'relu', 'initializer': {'name': 'default'}, 'regularizer': {'name': 'None'}}}, 'config': {'reward_shaper': {'scale_value': 0.1}, 'normalize_advantage': True, 'gamma': 0.99, 'tau': 0.9, 'learning_rate': 0.0002, 'name': 'cartpole_vel_info', 'score_to_win': 400, 'grad_norm': 1.0, 'entropy_coef': 0.01, 'truncate_grads': True, 'env_name': 'CartPole-v1', 'e_clip': 0.2, 'clip_value': True, 'num_actors': 16, 'horizon_length': 32, 'minibatch_size': 64, 'mini_epochs': 4, 'critic_coef': 1, 'lr_schedule': 'None', 'kl_threshold': 0.008, 'normalize_input': False, 'save_best_after': 10, 'device': 'cuda', 'multi_gpu': False}}}\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Load from file\n",
    "cfg = OmegaConf.load(\"../dependencies/rl_games/rl_games/configs/ppo_cartpole.yaml\")\n",
    "\n",
    "# Convert to a regular Python dict\n",
    "cfg_dict = OmegaConf.to_container(cfg, resolve=True)\n",
    "\n",
    "print(cfg_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eed8cc76-a6f2-4a18-8709-c8bdc14c316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {'params':\n",
    "               {'algo':\n",
    "                {'name': 'a2c_discrete'},\n",
    "                'model': {'name': 'discrete_a2c'},\n",
    "                'load_checkpoint': False,\n",
    "                'load_path': 'path',\n",
    "                'network':\n",
    "                {'name': 'actor_critic',\n",
    "                 'separate': True,\n",
    "                 'space': {'discrete': None},\n",
    "                 'mlp': {'units': [32, 32], 'activation': 'relu', 'initializer': {'name': 'default'}, 'regularizer': {'name': 'None'}}\n",
    "                },\n",
    "                'config':\n",
    "                {'reward_shaper': {'scale_value': 0.1},\n",
    "                 'normalize_advantage': True,\n",
    "                 'gamma': 0.99,\n",
    "                 'tau': 0.9,\n",
    "                 'learning_rate': 0.0002,\n",
    "                 'name': 'cartpole_vel_info',\n",
    "                 'score_to_win': 400,\n",
    "                 'grad_norm': 1.0,\n",
    "                 'entropy_coef': 0.01,\n",
    "                 'truncate_grads': True,\n",
    "                 'env_name': 'CartPole-v1',\n",
    "                 'e_clip': 0.2,\n",
    "                 'clip_value': True,\n",
    "                 'num_actors': 16,\n",
    "                 'horizon_length': 32,\n",
    "                 'minibatch_size': 64,\n",
    "                 'mini_epochs': 4,\n",
    "                 'critic_coef': 1,\n",
    "                 'lr_schedule': 'None',\n",
    "                 'kl_threshold': 0.008,\n",
    "                 'normalize_input': False,\n",
    "                 'save_best_after': 10,\n",
    "                 'device': 'cuda',\n",
    "                 'multi_gpu': False}\n",
    "               }\n",
    "              }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96e6e80a-77e6-4c14-aa01-e3c8bfd5c4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.seed = 1760958223\n"
     ]
    }
   ],
   "source": [
    "\n",
    "runner = Runner()\n",
    "runner.load_config(copy.deepcopy(config_dict['params']))\n",
    "runner.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa954b63-3a34-463b-87be-788e6aae674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = True\n",
    "runner.run({\n",
    "    'train': train,\n",
    "    'play': not train,\n",
    "    'checkpoint': '',\n",
    "    'sigma': None\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53bccfe-48f6-49d3-95e4-c0d9825eb143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24233cb9-b57d-44e4-bb67-bdfdc46e1ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from commonroad_dc import pycrcc\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2514363e-cb40-4bae-8621-56727e84ae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def commonroad_wall(wall):\n",
    "    \"\"\"\n",
    "    Used to create a wall for commonroad:\n",
    "    Input: line segment\n",
    "    Output: Oriented rectangle object\n",
    "    Steps:\n",
    "    1. Convert to the right input format\n",
    "    2. create the object\n",
    "    Oriented rectangle with width/2, height/2, orientation, x-position , y-position\n",
    "    x, y, ori, length = convert_coordinates(3, 3, 1, 2)\n",
    "    obb = pycrcc.RectOBB(length, .01, ori, x, y)\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = wall\n",
    "    # Calculate orientation\n",
    "    delta_x = x2 - x1\n",
    "    delta_y = y2 - y1\n",
    "    # Calculate length\n",
    "    length = (delta_x ** 2 + delta_y ** 2)**0.5\n",
    "    # origentation\n",
    "    orientation = np.arctan2(delta_y, delta_x)\n",
    "    #orientation = torch.arctan2(delta_y, delta_x)\n",
    "    # mid point\n",
    "    x = x1 + 0.5 * (x2 - x1)\n",
    "    y = y1 + 0.5 * (y2 - y1)\n",
    "    # wall width\n",
    "    width = .01\n",
    "    # __init__(self: commonroad_dc.pycrcc.RectOBB, width/2: float, height/2: float, orientation: float, center x: float, center y: float)â†’ None\n",
    "    obb = pycrcc.RectOBB(length/2, width/2, orientation, x, y)\n",
    "    return obb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cdf76d52-e046-4de4-a76c-ba5607ad66bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "def generate_random_walls(num_walls=10, \n",
    "                          xlim=(0, 100), \n",
    "                          ylim=(0, 100), \n",
    "                          min_length=0.5, \n",
    "                          max_length=3.0):\n",
    "    walls = []\n",
    "    for _ in range(num_walls):\n",
    "        # Pick a random starting point\n",
    "        x1 = random.uniform(*xlim)\n",
    "        y1 = random.uniform(*ylim)\n",
    "\n",
    "        # Random angle and length\n",
    "        angle = random.uniform(0, 360)\n",
    "        length = random.uniform(min_length, max_length)\n",
    "\n",
    "        # Compute endpoint\n",
    "        x2 = x1 + length * math.cos(math.radians(angle))\n",
    "        y2 = y1 + length * math.sin(math.radians(angle))\n",
    "\n",
    "        # Clamp endpoints within map bounds\n",
    "        x2 = max(xlim[0], min(x2, xlim[1]))\n",
    "        y2 = max(ylim[0], min(y2, ylim[1]))\n",
    "\n",
    "        walls.append((x1, y1, x2, y2))\n",
    "\n",
    "    return walls\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6250ad69-5487-465b-a8e2-924597cabfc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b7a781b7-823c-400e-aebb-14f1a9aac716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016901984214782714\n"
     ]
    }
   ],
   "source": [
    "tot_time = []\n",
    "\n",
    "for _ in range(100):\n",
    "    \n",
    "    walls = [commonroad_wall(wall) for wall in generate_random_walls(num_walls=10)]\n",
    "    \n",
    "    s_time = time.time()\n",
    "    cc = pycrcc.CollisionChecker()\n",
    "    for obstacle in walls:\n",
    "        cc.add_collision_object(obstacle)\n",
    "    \n",
    "    \n",
    "    #print(time.time() - s_time)\n",
    "    s_time2 = time.time()\n",
    "    \n",
    "    \n",
    "    field_of_view = 2* np.pi\n",
    "    num_ray_angles = 200 * 64\n",
    "    \n",
    "    ray_lines = np.linspace(field_of_view / 2, -field_of_view / 2, num_ray_angles)  # used by ROS Livox MID-360\n",
    "    \n",
    "    distances_list = np.zeros(num_ray_angles)\n",
    "    theta = 0\n",
    "    px = py = 0\n",
    "    max_range = 10\n",
    "    ray_angles = theta + ray_lines\n",
    "    \n",
    "    \n",
    "    ray_end_list = np.zeros((len(ray_angles), 2), dtype=np.float32)\n",
    "    ray_end_list[:, 0] = px + max_range * np.cos(ray_angles)\n",
    "    ray_end_list[:, 1] = py + max_range * np.sin(ray_angles)\n",
    "    \n",
    "    ray_hits_list = [cc.raytrace(px, py, ray_end[0], ray_end[1], False) for ray_end in ray_end_list]\n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(time.time() - s_time2)\n",
    "    tot_time.append(time.time() - s_time)\n",
    "print(np.mean(tot_time))\n",
    "\n",
    "# 10000 walls: 0.111\n",
    "# 10 walls: 0.0169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "88f81d69-b3aa-43b1-adb3-4e88f7d82e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3786.9822485207105\n",
      "576.5765765765766\n"
     ]
    }
   ],
   "source": [
    "print(64 * 1/0.0169)\n",
    "print(64 * 1/0.111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "116904ac-915e-42e7-aa49-7e0e59ce7bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "59ac4ee3-8467-4692-bfb2-9f0cb80cc286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.clip(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2680e79b-5b54-487c-941a-343ce2f4d5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
